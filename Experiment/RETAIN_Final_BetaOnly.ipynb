{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CDM_DataSetMaker_ops import get_conn\n",
    "from RETAIN_Dataset import convert_transaction_to_seq\n",
    "\n",
    "conn = get_conn('./DB_connection.txt')\n",
    "#T_seq = convert_transaction_to_seq(conn, 'condition_concept_id', 'HF_T_dx.pkl')\n",
    "#C_seq = convert_transaction_to_seq(conn, 'condition_concept_id', 'HF_C_dx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading at.. ./HF_T_dx.pkl\n",
      "Loading at.. ./HF_C_dx.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22548, 85011)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CDM_DataSetMaker_ops import loadingFiles\n",
    "\n",
    "T_seq = loadingFiles('./', 'HF_T_dx.pkl')\n",
    "C_seq = loadingFiles('./', 'HF_C_dx.pkl')\n",
    "\n",
    "len(T_seq), len(C_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_size:  5088\n"
     ]
    }
   ],
   "source": [
    "from RETAIN_Dataset_Final import truncated_data, code_to_id\n",
    "\n",
    "HF_T_cut = truncated_data(T_seq, cut_num=2)\n",
    "HF_C_cut = truncated_data(C_seq, cut_num=2)\n",
    "HF_code_dict, max_visit_size = code_to_id(HF_T_cut+HF_C_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RETAIN_Dataset_Final import RETAIN_datasets\n",
    "\n",
    "datasets = RETAIN_datasets(HF_T_cut, HF_C_cut, HF_code_dict, max_visit_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "time_size = max_visit_size\n",
    "code_size = len(HF_code_dict)\n",
    "label_size = 2\n",
    "lr_init = 0.0001\n",
    "decay_step = 2000\n",
    "decay_rate = 0.9\n",
    "training_step = 5000\n",
    "printby = 100\n",
    "\n",
    "hidden_size_alpha = 128\n",
    "hidden_size_beta = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def sequence_masking(data, visit_times):\n",
    "    masking = tf.tile(tf.reshape(tf.sequence_mask(visit_times, data.shape[1]), shape=[-1,data.shape[1],1]), [1,1,data.shape[2]])\n",
    "    return tf.where(masking, data, tf.zeros_like(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=[None, time_size, code_size])\n",
    "labels = tf.placeholder(tf.float32, shape=[None, time_size, label_size])\n",
    "visit_times = tf.placeholder(tf.float32, shape=[None])\n",
    "global_step = tf.Variable(0, trainable=False, dtype=tf.int32)\n",
    "lr = tf.train.exponential_decay(lr_init, global_step, decay_step, decay_rate, staircase=True)\n",
    "\n",
    "##embedding\n",
    "    \n",
    "##Beta\n",
    "W_beta = tf.Variable(tf.random_normal(shape=[hidden_size_beta, code_size]))\n",
    "b_beta = tf.Variable(tf.random_normal(shape=[code_size]))\n",
    "with tf.variable_scope('beta'):\n",
    "    cells_beta = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(hidden_size_beta)])\n",
    "    outputs_beta, states_beta = tf.nn.dynamic_rnn(cells_beta, inputs, visit_times, dtype=tf.float32)\n",
    "    reshaped_outputs_beta = tf.reshape(outputs_beta, shape=[-1, hidden_size_beta])\n",
    "    matmuled_ouputs_beta = tf.matmul(reshaped_outputs_beta, W_beta) + tf.expand_dims(b_beta, 0)\n",
    "    reshaped_matmuled_beta = tf.reshape(matmuled_ouputs_beta, shape=[-1, time_size, code_size])\n",
    "    logits_beta = tf.nn.tanh(reshaped_matmuled_beta)\n",
    "    \n",
    "##unifiy\n",
    "W_s = tf.Variable(tf.random_normal(shape=[code_size, label_size]))\n",
    "b_s = tf.Variable(tf.random_normal(shape=[label_size]))\n",
    "unified_context = logits_beta*inputs\n",
    "context_vec = []\n",
    "for b in range(batch_size):\n",
    "    pid_seq = unified_context[b]\n",
    "    for t in range(time_size):\n",
    "        context_vec.append(tf.reduce_sum(pid_seq[:t+1, :], axis=0))\n",
    "reshaped_context_vec = tf.reshape(context_vec, shape=[-1, code_size])\n",
    "mlp_context_vec = tf.matmul(reshaped_context_vec, W_s) + b_s\n",
    "logits = tf.nn.softmax(tf.reshape(mlp_context_vec, shape=[-1, time_size, label_size]))\n",
    "masked_logits = sequence_masking(logits, visit_times)\n",
    "masked_labels = sequence_masking(labels, visit_times)\n",
    "\n",
    "##Loss function\n",
    "loss_per_times = tf.reduce_sum(masked_labels*tf.log(masked_logits+1e-10)+(1-masked_labels)*tf.log(1-masked_logits+1e-10), axis=-1)\n",
    "loss_per_pid = tf.reduce_sum(loss_per_times, axis=-1)*(1/visit_times)\n",
    "last_loss = -tf.reduce_sum(loss_per_pid)*(1/batch_size)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(last_loss, global_step=global_step)\n",
    "\n",
    "##accuracy\n",
    "argmax_logits = tf.argmax(tf.reshape(masked_logits, shape=[-1,label_size]), axis=1)\n",
    "argmax_labels = tf.argmax(tf.reshape(masked_labels, shape=[-1,label_size]), axis=1)\n",
    "compared = tf.cast(tf.equal(argmax_logits, argmax_labels), tf.float32)\n",
    "accuracy = tf.reduce_mean(compared, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "with tf.Session() as sess:\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "    tf.global_variables_initializer().run(session=sess)\n",
    "\n",
    "    for step in trange(training_step):\n",
    "        batch_train_inputs, batch_train_labels, batch_train_visit_times = datasets.train.next_batch(batch_size)\n",
    "        batch_val_inputs, batch_val_labels, batch_val_visit_times = datasets.validation.next_batch(batch_size)\n",
    "        batch_te_inputs, batch_te_labels, batch_te_visit_times = datasets.test.next_batch(batch_size)\n",
    "        train_feed_dict = {inputs: batch_train_inputs, \n",
    "                           labels: batch_train_labels, \n",
    "                           visit_times: batch_train_visit_times}\n",
    "        validation_feed_dict = {inputs: batch_val_inputs, \n",
    "                                labels: batch_val_labels, \n",
    "                                visit_times: batch_val_visit_times}\n",
    "        test_feed_dict = {inputs: batch_te_inputs, \n",
    "                          labels: batch_te_labels, \n",
    "                          visit_times: batch_te_visit_times}\n",
    "        _, g_step, train_loss, train_lr_ = sess.run([optimizer, global_step, last_loss, lr], feed_dict=train_feed_dict)\n",
    "        val_loss, val_lr_ = sess.run([last_loss, lr], feed_dict=validation_feed_dict)\n",
    "        \n",
    "        if step % printby == 0:\n",
    "            print('step: {} \\tg_step: {} \\tloss: {:.8f}||{:.8f} \\tlr: {:.8f}||{:.8f}'.format(step, g_step, train_loss, val_loss, train_lr_, val_lr_))\n",
    "        \n",
    "        if step == training_step-1:\n",
    "            te_loss = sess.run(last_loss, feed_dict=test_feed_dict)\n",
    "            print('All Done! test_loss is {}'.format(te_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
